{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Facial Recognition With OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "* Python3 and OpenCV installed\n",
    "  * [Install on Mac](https://www.learnopencv.com/install-opencv3-on-macos/)\n",
    "  * [Install on Windows](https://www.learnopencv.com/install-opencv3-on-windows/)\n",
    "* Numpy and jupyter installed\n",
    "  * pip3 install numpy jupyter\n",
    "* A working webcam\n",
    "\n",
    "### Setup\n",
    "* Create 2 folders: _dataset_ and _trainer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and CV configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera - This will activate your camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX # Font for text on image\n",
    "\n",
    "# Face Classification Features\n",
    "face_cascade = cv2.CascadeClassifier('./classifiers/haar_frontal_face.xml')\n",
    "\n",
    "# Training Data Path\n",
    "dataset_path = 'targets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Data Gathering\n",
    "\n",
    "This will take 30 pictures of the face you'd like to recognize. They will be labeled with the name you give it in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Please enter your name and press <return> ==>  1\n"
     ]
    }
   ],
   "source": [
    "# Known Faces\n",
    "known_faces = {} # Image Id => Person's name\n",
    "\n",
    "face_name = input('\\n Please enter your name and press <return> ==>  ')\n",
    "face_id = random.randint(1, 1000)\n",
    "known_faces[face_id] = face_name\n",
    "\n",
    "sample_count = 0\n",
    "\n",
    "# Take 30 snapshots of face for training\n",
    "while(True):\n",
    "    ret, img = cam.read() # capture an image\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to gray so its easier to process\n",
    "    \n",
    "    # use Haar features to find faces in the image. \n",
    "    found_faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=5, minSize=(20, 20))\n",
    "    \n",
    "    # Found faces is returned as the x, y coord of the upper left corner of the face and w, h of the face boundary\n",
    "    for(x, y, w, h) in found_faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # draw a blue rectangle on the color image\n",
    "        sample_count += 1 # keep track of how many shots we took\n",
    "        \n",
    "        # Save the slice of the grayscale image that is the face in the dataset folder\n",
    "        cv2.imwrite(\"./\"+ dataset_path +\"/\" + face_name + \".\" + str(face_id) + \".\" + str(sample_count) + \".jpg\", gray_img[y:y+h, x:x+w])\n",
    "    \n",
    "    # Show us the image so we can adjust position as necessary\n",
    "    cv2.imshow('frame', img)\n",
    "    \n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif sample_count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Stop capturing the image\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "with open('known_faces.json', 'w') as outfile:\n",
    "    json.dump(known_faces, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Training Images to Create LBP Histogram\n",
    "\n",
    "The LBP Histogram is essentially the numerical signature for your face. This is the baseline that the camera will compare your video feed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "known_faces = {}\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        img_numpy = np.array(gray_image,'uint8')\n",
    "        face_name = (os.path.split(imagePath)[-1].split(\".\")[0])\n",
    "        id = int((os.path.split(imagePath)[-1].split(\".\")[1]))\n",
    "        known_faces[id] = face_name\n",
    "        faces = face_cascade.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "faces,ids = getImagesAndLabels('targets')\n",
    "recognizer.train(faces, np.array(ids))\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "\n",
    "# Print an example of what a face looks like in the context of Local Binary Pattern\n",
    "# image = cv2.imread([os.path.join(dataset_path,f) for f in os.listdir(dataset_path)][2])\n",
    "# gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# features = feature.local_binary_pattern(gray_image, 10, 5, method=\"default\")\n",
    "# cv2.imwrite(\"./lbp_image.png\", features.astype(\"uint8\"))\n",
    "\n",
    "# with open('known_faces.json', 'w') as outfile:\n",
    "#     json.dump(known_faces, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and Identify Faces\n",
    "\n",
    "You may need to restart the notebook to make this work. This opens a camera feed and detects _any face_ and turns that into a histogram and compares this histogram to all the histograms the recongizer knows about from _trainer.yml_. The closest result using the Euclidean difference (square root of sum of squares) within reason and assigns the label accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ab48c8d89f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m \u001b[0;31m# Press 'ESC' for exiting video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "\n",
    "# Camera - This will activate your camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX # Font for text on image\n",
    "\n",
    "with open('known_faces.json') as infile:\n",
    "    known_faces = json.load(infile)\n",
    "    \n",
    "# Face Classification Features\n",
    "face_cascade = cv2.CascadeClassifier('./classifiers/haar_frontal_face.xml')\n",
    "\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(20, 20))\n",
    "    \n",
    "    for(x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 225, 0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h, x:x+w])\n",
    "        if(confidence < 100):\n",
    "            id = known_faces[str(id)]\n",
    "            confidence = \" {0}%\".format(round(100-confidence))\n",
    "        else:\n",
    "            id = \"unk\"\n",
    "            confidence = \" {0}%\".format(round(100-confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5, y-5), font, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5, y+h-5), font, 1, (255, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "        \n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
